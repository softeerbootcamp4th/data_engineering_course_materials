### **Hadoop 환경 설정 및 작업 실행**

1. **Hadoop 환경 설정**:
    - Hadoop이 설치되어 있는지 확인.
    - HDFS 및 YARN 서비스가 실행 중인지 확인.
2. **전자책 업로드**:
    
    ```bash
    hdfs dfs -mkdir -p /input
    hdfs dfs -ls /input
    hdfs dfs -put /usr/local/hadoop/ebook.txt /input
    /usr/local/hadoop/ebook.txt
    
    hdfs dfs -put /user/hadoop/input/ebook.txt /user/hadoop/input/ebook.txt
    ```

- 전자책 정보

- **책 이름**: Mastering Hadoop
- **출처**:  Sandeep Karanth


    
3. **MapReduce 작업 실행**:
    
    ```bash
    hdfs dfs -put /usr/local/hadoop/mapper.py /user/hadoop/mapper.py
    hdfs dfs -put /usr/local/hadoop/reducer.py /user/hadoop/reducer.py
    
    chmod +x /usr/local/hadoop/sbin/mapreducer.sh
    /usr/local/hadoop/sbin/mapreducer3.sh
    
    ```
    
4. **결과 확인**:
    
    ```bash
    
    hdfs dfs -cat /user/hadoop/output/part-00000
    
    ```
    
    ![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/6ec20228-be51-4a9f-a5f2-85b8c55a6714/a9b4d97a-810a-4d27-b7bc-5c996aecd699/Untitled.png)
    

### 리듀스 작업 요약

- **맵 작업**: 16520개의 입력 레코드를 처리하고 88301개의 출력 레코드를 생성했습니다.
- **리듀스 작업**: 88301개의 입력 레코드를 받아 12948개의 출력 레코드를 생성했습니다.
- **HDFS 입출력**: 총 1198062 바이트를 읽고 179262 바이트를 썼습니다.

### **README 파일 예시**

### **README.md**

```


### 2. 전자책 업로드
200페이지 이상의 영어 전자책을 `ebook.txt`로 저장한 후 HDFS에 업로드합니다:
```bash
hdfs dfs -mkdir /user/hadoop/input
hdfs dfs -put ebook.txt /user/hadoop/input

```

### 3. MapReduce 작업 실행

```bash

hadoop jar /usr/local/hadoop/share/hadoop/tools/lib/hadoop-streaming-*.jar \
-mapper mapper.py \
-reducer reducer.py \
-input /user/hadoop/input/ebook.txt \
-output /user/hadoop/output

```

### 4. 결과 확인

```bash
bash코드 복사
hdfs dfs -cat /user/hadoop/output/part-00000

```

### **출력을 해석하고 결과를 검증하는 방법**

- 출력 파일의 각 줄에는 단어와 해당 단어의 개수가 탭으로 구분되어 있습니다.
- 출력 파일 예시:
    
    ```python
    python코드 복사
    word1   150
    word2   300
    ...
    
    ```
    
- 출력 결과를 검증하려면 특정 단어의 개수가 정확한지 확인할 수 있습니다.
- 예를 들어, `grep` 명령어를 사용하여 특정 단어를 필터링할 수 있습니다.
    
    ```bash
    bash코드 복사
    hdfs dfs -cat /user/hadoop/output/part-00000 | grep "data"
    
    ```
    

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/6ec20228-be51-4a9f-a5f2-85b8c55a6714/9c529a4e-dfab-4ac4-89f4-98c798daa0c6/Untitled.png)
