# ETL 프로세스 구현
> generated 디렉터리를 만들어야 합니다.

웹 스크래핑(수집) -> 프로세싱(가공) -> DB(저장)의 파이프라인을 구성한다.

**시나리오**  
- 당신은 해외로 사업을 확장하고자 하는 기업에서 Data Engineer로 일하고 있습니다. 경영진에서 **GDP가 높은 국가**들을 대상으로 사업성을 평가하려고 합니다.  
- 이 자료는 앞으로 경영진에서 지속적으로 요구할 것으로 생각되기 때문에 **자동화된 스크립트**를 만들어야 합니다.

**기능요구사항**
- IMF에서 제공하는 국가별 GDP를 구하세요. [wiki](https://en.wikipedia.org/wiki/List_of_countries_by_GDP_%28nominal%29)
- 국가별 GDP를 확인할 수 있는 테이블을 만드세요.
- 해당 테이블에는 GDP가 높은 국가들이 먼저 나와야 합니다.
- GDP의 단위는 1B USD이어야 하고 소수점 2자리까지만 표시해 주세요.
- IMF에서 매년 2회 이 자료를 제공하기 때문에 정보가 갱신되더라도 해당 코드를 재사용해서 정보를 얻을 수 있어야 합니다.

**화면 출력**
- GDP가 100B USD이상이 되는 국가만을 구해서 화면에 출력해야 합니다.
- 각 Region별로 top5 국가의 GDP 평균을 구해서 화면에 출력해야 합니다.

**주의**
- 함수를 분리하여 작성
- 주석으로 설명달기


# 팀 활동 요구사항
1. wikipeida 페이지가 아닌, IMF 홈페이지에서 직접 데이터를 가져오는 방법은 없을까요? 어떻게 하면 될까요?  
IMF DATA에서 관련된 API를 제공한다. 가능하다면 API 키를 받아 사용하는 것이 베스트  
API 키 발급이 어렵다면 IMF 홈페이지에서 제공하는 레포트 작성 기능(쿼리)을 셀레니움을 통해 자동화할 수 있다.  
[IMF WEO](https://www.imf.org/en/Publications/WEO/weo-database/2024/April)

2. 만약 데이터가 갱신되면 과거의 데이터는 어떻게 되어야 할까요? 과거의 데이터를 조회하는 게 필요하다면 ETL 프로세스를 어떻게 변경해야 할까요?  
>지금은 한 번에 200건 정도밖에 되지 않지만 데이터가 굉장히 많다고 가정  

우선, ETL 프로세스와 보고서 작성(리전별 상위 5개국 평균, GDP 100B 이상)을 위한 스크립트를 분리한다.  
데이터가 갱신되지 않았다는 가정하에 ETL 프로그램은 보고서 작성을 위해 매 번 호출될 필요가 없다.  
즉, ETL 프로세스는 데이터가 갱신되었을 때만 동작하며 일상적인 보고서 작성은 따로 분리된 스크립트(DB 조회하는)를 통해서만 동작한다.
<br>

위와 같은 가정아래 GDP 데이터가 갱신되어 데이터베이스에 새로 데이터를 쓰려고 할 때, 기존의 데이터는 어떻게 해야할까?  
일상적이진 않지만 과거 데이터를 조회해야 하는 일이 있다면 그에 대한 데이터는 어딘가 반드시 저장되어야 한다.  
<br>
가장 단순하게는 기존의 테이블에 데이터를 스크랩한 날짜와 IMF가 제공하는 데이터의 연도, (데이터가 상/하반기로 갱신된다면)분기를 나타내는 심볼을 함께 저장하면 된다.  
연도와 분기를 통해 알고싶은 데이터를 찾을 수 있을 것이다.  
<br>
다만, 대량의 데이터가 될 경우 한 테이블에서 모든 데이터를 찾기란 느리고 비효율적인 일이 될 것이다.  
일상적으로 필요한 최신의 데이터 이외의 나머지 과거 데이터는 그 접근 빈도수가 적지만, 모든 데이터를 한 곳에 몰아두면 조회가 함께 느려진다는 문제가 있다.  
<br>
이를 해결하기 위해 최근 데이터만을 모아두는 테이블을 만드는 방법을 사용할 수 있다.  
즉, 새로 갱신된 데이터는 최신 데이터 테이블과 아카이브 테이블 두 곳에 저장한다.  
일상적인 조회는 최신 데이터 테이블에서 수행하고, 가끔 필요한 과거 데이터에 대한 조회는 아카이브 테이블을 사용토록한다.  
이렇게하면 전체 데이터 수와 무관하게 최신 데이터 테이블의 크기를 일정하게 유지하여 일상적인 조회 성능을 보장받을 수 있다.  