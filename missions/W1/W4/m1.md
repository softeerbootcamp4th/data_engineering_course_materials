## **클러스터 설정 가이드**

### 1. Dockerfile 작성

Spark 이미지를 빌드하기 위한 `Dockerfile`

이 파일은 Spark를 포함한 Docker 이미지를 생성합니다. Spark의 설치, 환경 설정, 필요 패키지 설치 등을 수행합니다.

### 2. Docker Compose 파일 작성

Spark 클러스터를 설정하기 위한 `docker-compose.yml`

이 파일은 여러 컨테이너(Spark Master, Spark Worker, Spark History Server 등)를 정의하고 설정합니다.

`entrypoint.sh`

### 3. entrypoint.sh

각 컨테이너에서 실행될 명령어를 포함한 스크립트입니다. 컨테이너가 시작될 때 실행되며, Spark Master, Worker, History Server 등을 시작합니다.

### 4. start-spark.sh 스크립트 작성

 `start-spark.sh` 스립트의 예입니다.

이 스크립트는 Spark Master, Worker, History Server를 시작합니다.

### 5 Spark 작업 제출 스크립트 작성

π 추정을 수행하고 결과를 CSV 형식으로 저장하는 Spark 작업 스크립트의 예입니다. 이 스크립트를 `pi_to_csv.py`라는 파일로 저장

### 6.submit-pi-job.sh 스크립트 작성

위에서 작성한 Spark 작업을 제출

## **설정 및 실행**

1. Docker 이미지를 빌드합니다.

```python
cd /users/admin/softeer/week4/m1
docker build --platform=linux/amd64 -t spark:latest .

```

1. Docker Compose를 사용하여 클러스터를 시작합니다.

```python
			docker-compose down
docker-compose up -d
```

1. Spark 작업을 제출합니다.

```python
		
./submit-pi-job.sh

```

1. Spark 웹 UI를 통해 작업을 모니터링합니다.

```python
http://localhost:8080

```

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/6ec20228-be51-4a9f-a5f2-85b8c55a6714/07294a10-ff70-4124-ae12-774da33e4e7e/Untitled.png)

```python
http://localhost:18080

```

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/6ec20228-be51-4a9f-a5f2-85b8c55a6714/d121b342-8f7b-40a4-bfdb-08ac4b3be164/Untitled.png)

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/6ec20228-be51-4a9f-a5f2-85b8c55a6714/e8d4fa6d-e265-410f-9928-4176ad84bb6e/Untitled.png)

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/6ec20228-be51-4a9f-a5f2-85b8c55a6714/7f468caa-0662-42e8-8c52-bbd63f311c3f/Untitled.png)

```python
docker exec -it spark-master bash
cat data/output/part-00019-a10f6a06-735a-4b77-a2ce-bf57be813e3f-c000.csv

cat usr/local/spark/work-dir/montecarlo_result_20240725074906.csv
```

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/6ec20228-be51-4a9f-a5f2-85b8c55a6714/81bc2dd1-5718-4270-834d-1669980e0f8d/Untitled.png)

## **오류 처리 및 로그 접근**

- **네트워크 문제 해결**: Docker Compose를 사용하면 컨테이너 간 네트워크 문제를 자동으로 관리합니다.
- **로그 접근**: 각 컨테이너의 로그 파일은 `/usr/local/spark/logs/` 디렉토리에 저장됩니다. 컨테이너 내부에서 로그를 확인하려면 다음 명령어를 사용하세요.
- source myenv/bin/activate

```python
docker exec -it spark-master tail -f /usr/local/spark/logs/spark--org.apache.spark.deploy.master.Master-1-spark-master.out

```

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/6ec20228-be51-4a9f-a5f2-85b8c55a6714/bc883128-ce36-44c0-b5bc-543b6b5eae67/Untitled.png)

## **재현성 보장**

- 제공된 Dockerfile과 docker-compose.yml을 사용하여 전체 설정을 재현할 수 있습니다.
- 위의 명확한 지침을 따라 Docker 이미지를 빌드하고, 클러스터를 시작하고, 작업을 제출하고, 결과를 확인할 수 있습니다.