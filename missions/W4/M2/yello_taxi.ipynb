{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-26T01:19:57.159780Z",
     "start_time": "2024-07-26T01:19:54.308015Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import os\n",
    "\n",
    "os.environ[\"PYARROW_IGNORE_TIMEZONE\"] = \"1\"\n",
    "\n",
    "WORK_DIR = os.getcwd()\n",
    "spark = SparkSession.builder.appName(\"TaxiDataAnalysis\").master(\"local[*]\").getOrCreate()\n",
    "ride_df = spark.read.parquet(f'file:///{WORK_DIR}/yellow_taxi.parquet')\n",
    "\n",
    "# Data Cleaning and Transformation\n",
    "ride_df = ride_df.dropna()  # 결측치 제거\n",
    "\n",
    "# 음수 값 필터링\n",
    "ride_df = ride_df.filter(\n",
    "    (col(\"trip_distance\") > 0) &\n",
    "    (col(\"fare_amount\") > 0) &\n",
    "    (col(\"total_amount\") > 0) &\n",
    "    (col(\"passenger_count\") > 0)\n",
    ")\n",
    "\n",
    "# 의미 없는 컬럼 삭제\n",
    "ride_df = ride_df.drop(\"VendorID\", \"RatecodeID\", \"store_and_fwd_flag,\", \"PULocationID\", \"DOLocationID\", \"payment_type\")\n",
    "\n",
    "# 여행 시간 계산 (분 단위)\n",
    "ride_df = ride_df.withColumn(\n",
    "    \"trip_duration_minutes\",\n",
    "    (unix_timestamp(col(\"tpep_dropoff_datetime\")) - unix_timestamp(col(\"tpep_pickup_datetime\"))) / 60\n",
    ")\n",
    "\n",
    "# Metrics Calculation\n",
    "metrics = ride_df.agg(\n",
    "    avg(\"trip_duration_minutes\").alias(\"avg_trip_duration\"),\n",
    "    avg(\"trip_distance\").alias(\"avg_trip_distance\")\n",
    ")\n",
    "\n",
    "metrics.show()"
   ],
   "id": "458402d8f280840e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----------------+\n",
      "| avg_trip_duration|avg_trip_distance|\n",
      "+------------------+-----------------+\n",
      "|15.763545132636214|3.302459328035664|\n",
      "+------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Peak Hours Analysis\n",
    "hourly_trips = ride_df.groupBy(hour(\"tpep_pickup_datetime\").alias(\"hour\")) \\\n",
    "    .agg(count(\"*\").alias(\"trip_count\")) \\\n",
    "    .orderBy(\"hour\")\n",
    "\n",
    "hourly_trips.show()"
   ],
   "id": "ac88fa2777d8b1f0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 결과 저장\n",
    "metrics.write.csv(f\"file:///{WORK_DIR}/metrics.csv\",\n",
    "                  header=True, mode='overwrite')\n",
    "hourly_trips.write.csv(\n",
    "    f\"file:///{WORK_DIR}/hourly_trips.csv\", header=True, mode='overwrite')"
   ],
   "id": "93422f0cffbae236",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 시각화\n",
    "hourly_trips_pd = hourly_trips.toPandas()\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(hourly_trips_pd[\"hour\"], hourly_trips_pd[\"trip_count\"])\n",
    "plt.title(\"Number of Trips by Hour\")\n",
    "plt.xlabel(\"Hour of Day\")\n",
    "plt.ylabel(\"Number of Trips\")\n",
    "plt.savefig(f\"{WORK_DIR}/hourly_trips.png\")\n",
    "plt.show()"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def fetch_weather_data(date):\n",
    "    url = f\"https://www.timeanddate.com/scripts/cityajax.php?n=usa/new-york&mode=historic&hd={date}&month={date[4:6]}&year={date[:4]}&json=1\"\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.159 Safari/537.36\",\n",
    "        \"Accept-Language\": \"en-US,en;q=0.5\"\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, headers=headers).text.replace(\"c:\", \"\\\"c\\\":\").replace(\"s:\", \"\\\"s\\\":\").replace(\"h:\",\n",
    "                                                                                                               \"\\\"h\\\":\")\n",
    "    data = json.loads(response)\n",
    "    weather_data = []\n",
    "    for entry in data:\n",
    "        row = {'time': entry['c'][0]['h'][:5], 'temperature(°C)': entry['c'][2]['h'].replace(\"&nbsp;°C\", \"\").strip(),\n",
    "               'description': entry['c'][3]['h'], 'wind_speed(km/h)': entry['c'][4]['h'].replace(\"km/h\", \"\").strip(),\n",
    "               'humidity(%)': entry['c'][6]['h'].replace(\"%\", \"\").strip(),\n",
    "               'barometer(mbar)': entry['c'][7]['h'].replace(\"mbar\", \"\").strip(),\n",
    "               'visibility(km)': entry['c'][8]['h'].replace(\"&nbsp;km\", \"\").strip()}\n",
    "        weather_data.append(row)\n",
    "\n",
    "    # Convert list of dictionaries to DataFrame\n",
    "    df = spark.createDataFrame(weather_data)\n",
    "    df.write.csv(f'./weather/{date}', header=True, mode='overwrite')\n",
    "    print(f\"{date} weather data saved\")\n",
    "    return weather_data\n",
    "\n",
    "\n",
    "def collect_weather_data(start_date, end_date):\n",
    "    all_data = []\n",
    "    current_date = start_date\n",
    "    while current_date <= end_date:\n",
    "        date_str = current_date.strftime('%Y%m%d')\n",
    "        data = fetch_weather_data(date_str)\n",
    "        all_data.extend(data)\n",
    "        current_date += timedelta(days=1)\n",
    "    return all_data\n",
    "\n",
    "\n",
    "start_date = datetime(2024, 1, 1)\n",
    "end_date = datetime(2024, 1, 31)\n",
    "all_data = collect_weather_data(start_date, end_date)"
   ],
   "id": "4d0951046c9a5c8d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 1. 날씨 데이터를 로드하고 택시 데이터와 시간을 기준으로 조인\n",
    "def read_weather_data(start_date, end_date):\n",
    "    unioned = spark.read.csv(f'file:///{WORK_DIR}/weather/{start_date.strftime('%Y%m%d')}', header='true')\n",
    "    unioned = unioned.withColumn(\"datetime\",\n",
    "                                 to_timestamp(concat(lit(f\"{start_date.strftime('%Y-%m-%d')} \"), col(\"time\")),\n",
    "                                              \"yyyy-MM-dd HH:mm\"))\n",
    "    current_date = start_date + timedelta(days=1)\n",
    "    while current_date <= end_date:\n",
    "        date_str = current_date.strftime('%Y%m%d')\n",
    "        weather_df = spark.read.csv(f'file:///{WORK_DIR}/weather/{date_str}', header='true')\n",
    "        weather_df = weather_df.withColumn(\"datetime\", to_timestamp(\n",
    "            concat(lit(f\"{current_date.strftime('%Y-%m-%d')} \"), col(\"time\")), \"yyyy-MM-dd HH:mm\"))\n",
    "        unioned = unioned.union(weather_df)\n",
    "        current_date += timedelta(days=1)\n",
    "    unioned.orderBy(col(\"datetime\"))\n",
    "    return unioned\n",
    "\n",
    "\n",
    "def join_weather_ride(weather_df, ride_df):\n",
    "    # 윈도우 정의\n",
    "    window_spec = Window.orderBy(\"datetime\")\n",
    "    # 이전 및 다음 행의 datetime 값 가져오기\n",
    "    weather_df = weather_df.withColumn(\"prev_datetime\", lag(\"datetime\").over(window_spec)) \\\n",
    "        .withColumn(\"next_datetime\", lead(\"datetime\").over(window_spec))\n",
    "    # 중간 시각 계산\n",
    "    weather_df = weather_df.withColumn(\"start\", expr(\n",
    "        \"CASE WHEN prev_datetime IS NOT NULL THEN (prev_datetime + (datetime - prev_datetime) / 2) ELSE datetime END\")) \\\n",
    "        .withColumn(\"end\", expr(\n",
    "        \"CASE WHEN next_datetime IS NOT NULL THEN (datetime + (next_datetime - datetime) / 2) ELSE datetime END\")) \\\n",
    "        .drop(\"prev_datetime\", \"next_datetime\", \"time\")\n",
    "    # 탑승 시간 형식 변환\n",
    "    ride_df = ride_df.withColumn(\"tpep_pickup_datetime\",\n",
    "                                 to_timestamp(col(\"tpep_pickup_datetime\"), \"yyyy-MM-dd HH:mm:ss.SSSSSS\")) \\\n",
    "        .withColumn(\"tpep_dropoff_datetime\",\n",
    "                    to_timestamp(col(\"tpep_dropoff_datetime\"), \"yyyy-MM-dd HH:mm:ss.SSSSSS\"))\n",
    "    # 탑승 데이터와 날씨 데이터를 시간에 따라 조인\n",
    "    joined_df = ride_df.join(weather_df,\n",
    "                             (ride_df[\"tpep_pickup_datetime\"] >= weather_df[\"start\"]) &\n",
    "                             (ride_df[\"tpep_pickup_datetime\"] < weather_df[\"end\"]),\n",
    "                             how=\"left\")\n",
    "    return joined_df\n",
    "\n",
    "\n",
    "weather_df = read_weather_data(start_date, end_date)\n",
    "joined_df = join_weather_ride(weather_df, ride_df)\n"
   ],
   "id": "a51148c2843601df",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 데이터 타입 변환\n",
    "joined_df = joined_df.withColumn(\"tpep_pickup_datetime\", col(\"tpep_pickup_datetime\").cast(TimestampType())) \\\n",
    "    .withColumn(\"tpep_dropoff_datetime\", col(\"tpep_dropoff_datetime\").cast(TimestampType())) \\\n",
    "    .withColumn(\"passenger_count\", col(\"passenger_count\").cast(IntegerType())) \\\n",
    "    .withColumn(\"trip_distance\", col(\"trip_distance\").cast(DoubleType())) \\\n",
    "    .withColumn(\"store_and_fwd_flag\", col(\"store_and_fwd_flag\").cast(StringType())) \\\n",
    "    .withColumn(\"fare_amount\", col(\"fare_amount\").cast(DoubleType())) \\\n",
    "    .withColumn(\"extra\", col(\"extra\").cast(DoubleType())) \\\n",
    "    .withColumn(\"mta_tax\", col(\"mta_tax\").cast(DoubleType())) \\\n",
    "    .withColumn(\"tip_amount\", col(\"tip_amount\").cast(DoubleType())) \\\n",
    "    .withColumn(\"tolls_amount\", col(\"tolls_amount\").cast(DoubleType())) \\\n",
    "    .withColumn(\"improvement_surcharge\", col(\"improvement_surcharge\").cast(DoubleType())) \\\n",
    "    .withColumn(\"total_amount\", col(\"total_amount\").cast(DoubleType())) \\\n",
    "    .withColumn(\"congestion_surcharge\", col(\"congestion_surcharge\").cast(DoubleType())) \\\n",
    "    .withColumn(\"Airport_fee\", col(\"Airport_fee\").cast(DoubleType())) \\\n",
    "    .withColumn(\"trip_duration_minutes\", col(\"trip_duration_minutes\").cast(DoubleType())) \\\n",
    "    .withColumn(\"barometer(mbar)\", col(\"barometer(mbar)\").cast(DoubleType())) \\\n",
    "    .withColumn(\"description\", col(\"description\").cast(StringType())) \\\n",
    "    .withColumn(\"humidity(%)\", col(\"humidity(%)\").cast(IntegerType())) \\\n",
    "    .withColumn(\"temperature(°C)\", col(\"temperature(°C)\").cast(DoubleType())) \\\n",
    "    .withColumn(\"visibility(km)\", col(\"visibility(km)\").cast(DoubleType())) \\\n",
    "    .withColumn(\"wind_speed(km/h)\", col(\"wind_speed(km/h)\").cast(DoubleType())) \\\n",
    "    .withColumn(\"datetime\", col(\"datetime\").cast(TimestampType())) \\\n",
    "    .withColumn(\"start\", col(\"start\").cast(TimestampType())) \\\n",
    "    .withColumn(\"end\", col(\"end\").cast(TimestampType()))\n",
    "\n",
    "weather_df.write.csv(f'./weather/January', header=True, mode='overwrite')\n",
    "joined_df.write.csv(f'./joined/January', header=True, mode='overwrite')"
   ],
   "id": "ad9e324bfcdd1d54",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 날씨와 요금 간의 상관관계 분석\n",
    "correlation = joined_df.select(corr(\"total_amount\", \"temperature(°C)\").alias(\"correlation\")).collect()[0][\"correlation\"]\n",
    "print(f\"Correlation between total amount and temperature: {correlation}\")"
   ],
   "id": "730f7c831dfbfe50",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 1. 날씨 데이터를 로드하고 택시 데이터와 시간을 기준으로 조인\n",
    "# 2. 날씨 조건(예: 온도, 강수량)과 여행 수 간의 상관관계 분석\n",
    "# 3. 날씨 조건에 따른 여행 수 변화를 시각화\n",
    "\n",
    "# 각 날씨 조건별로 여행 수 계산\n",
    "weather_trip_counts = joined_df.groupBy(\"temperature(°C)\", \"description\").agg(\n",
    "    count(\"tpep_pickup_datetime\").alias(\"trip_count\"))\n",
    "weather_trip_counts.show()\n",
    "# 상관관계 분석\n",
    "correlation_temp_trip_count = \\\n",
    "    weather_trip_counts.select(corr(\"temperature(°C)\", \"trip_count\").alias(\"correlation\")).collect()[0][\"correlation\"]\n",
    "print(f\"Correlation between temperature and trip count: {correlation_temp_trip_count}\")"
   ],
   "id": "3f92cb418987bbd0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "pandas_df = weather_trip_counts.toPandas().dropna()\n",
    "pandas_df[\"temperature(°C)\"] = pandas_df[\"temperature(°C)\"].astype(float)\n",
    "pandas_df.groupby(\"temperature(°C)\").sum(\"trip_count\").sort_values(by=\"temperature(°C)\").plot(kind='bar')"
   ],
   "id": "75331de5eac92a0b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# SparkSession 종료\n",
    "spark.stop()"
   ],
   "id": "1506779af9e35e1f",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
