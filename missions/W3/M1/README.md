## SINGLE NODE HADOOP CLUSTER

### **Docker Image build & Run container**

싱글 노드 하둡 클러스터를 위한 이미지를 구축하였습니다. 컨테이너가 실행될 때 하둡의 서비스를 바로 이용할 수 있습니다. 포트 개방을 통해 호스트 머신과의 http 통신이 가능합니다.

### **HDFS Operations**

도커 컨테이너 내부에서 하둡 파일시스템을 사용할 수 있습니다. 호스트 운영체제에서 ssh 연결을 통해 컨테이너 내부에 접근할 수 있습니다. 디렉토리 생성, 파일 업로드, 검색이 가능합니다. 호스트 운영체제에서 웹 인터페이스에 접근할 수 있습니다.

### **Persistence**

“Volumes are the preferred mechanism for persisting data generated by and used by Docker containers. While [bind mounts](https://docs.docker.com/storage/bind-mounts/) are dependent on the directory structure and OS of the host machine, volumes are completely managed by Docker. Volumes have several advantages over bind mounts:” - “도커 docs에서 발췌”

[Volumes](https://docs.docker.com/storage/volumes/#use-a-volume-driver)

데이터의 영속성을 위해 ‘bind mounts’와 ‘docker volume’을 사용할 수 있습니다. 컨테이너의 데이터는 격리되어있으며 컨테이너 내부의 데이터는 컨테이너 외부 혹은 다른 컨테이너에서 접근할 수 없습니다. bind mounts와 docker volume을 통해 컨테이너 내부의 데이터를 호스트에서 접근할 수 있도록 합니다. 미션에서는 bind mounts를 사용하여 컨테이너를 run 하였습니다. 컨테이너의 $HADOOP_HOME/data 디렉토리는 호스트 머신의 /Users/admin/hadoop_data 디렉토리와 마운트 되어있습니다.

### 

### 이미지 빌드를 위한 도커파일, 하둡 설정 파일

- Dockerfile

```bash
# Base image
FROM ubuntu:22.04

# Install necessary packages
RUN apt-get update && \
    apt-get install -y openjdk-11-jdk wget ssh rsync sudo && \
    apt-get clean

# Create Hadoop user
RUN useradd -ms /bin/bash hadoop
RUN echo "hadoop ALL=(ALL) NOPASSWD:ALL" >> /etc/sudoers

# Set environment variables
ENV JAVA_HOME /usr/lib/jvm/java-11-openjdk-arm64
ENV HADOOP_VERSION 3.3.6
ENV HADOOP_HOME /usr/local/hadoop
ENV HADOOP_COMMON_LIB_NATIVE_DIR $HADOOP_HOME/lib/native
ENV PATH $PATH:$HADOOP_HOME/bin

# Download and install Hadoop
RUN wget https://downloads.apache.org/hadoop/common/hadoop-$HADOOP_VERSION/hadoop-$HADOOP_VERSION.tar.gz && \
    tar -xzvf hadoop-$HADOOP_VERSION.tar.gz && \
    mv hadoop-$HADOOP_VERSION $HADOOP_HOME && \
    rm hadoop-$HADOOP_VERSION.tar.gz && \
    chown -R hadoop:hadoop $HADOOP_HOME

# Change user
USER hadoop

# Configure SSH
RUN ssh-keygen -t rsa -P '' -f /home/hadoop/.ssh/id_rsa && \
    cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys && \
    chmod 600 ~/.ssh/authorized_keys

# Set environment variables in .bashrc
RUN echo "export JAVA_HOME=/usr/lib/jvm/java-11-openjdk-arm64" >> ~/.bashrc && \
    echo "export HADOOP_VERSION=3.3.6" >> ~/.bashrc && \
    echo "export HADOOP_HOME=/usr/local/hadoop" >> ~/.bashrc && \
    echo "export HADOOP_INSTALL=\$HADOOP_HOME" >> ~/.bashrc && \
    echo "export HADOOP_MAPRED_HOME=\$HADOOP_HOME" ~/.bashrc && \
    echo "export HADOOP_COMMON_HOME=\$HADOOP_HOME" ~/.bashrc && \
    echo "export HADOOP_HDFS_HOME=\$HADOOP_HOME" ~/.bashrc && \
    echo "export HADOOP_YARN_HOME=\$HADOOP_HOME" ~/.bashrc && \
    echo "export HADOOP_COMMON_LIB_NATIVE_DIR=\$HADOOP_HOME/lib/native" >> ~/.bashrc && \
    echo "export PATH=\$PATH:\$HADOOP_HOME/bin" >> ~/.bashrc

# Add Hadoop configuration files
COPY core-site.xml $HADOOP_HOME/etc/hadoop/core-site.xml
COPY hdfs-site.xml $HADOOP_HOME/etc/hadoop/hdfs-site.xml
COPY mapred-site.xml $HADOOP_HOME/etc/hadoop/mapred-site.xml
COPY yarn-site.xml $HADOOP_HOME/etc/hadoop/yarn-site.xml

# Configure JAVA_HOME in Hadoop environment
RUN echo "export JAVA_HOME=$JAVA_HOME" >> $HADOOP_HOME/etc/hadoop/hadoop-env.sh

# Format HDFS namenode
RUN sudo mkdir -p /usr/local/hadoop/data/namenode && \
    sudo mkdir -p /usr/local/hadoop/data/datanode && \
    sudo chown -R hadoop:hadoop /usr/local/hadoop/data && \
    $HADOOP_HOME/bin/hdfs namenode -format

# Add entrypoint script
COPY entrypoint.sh /entrypoint.sh
RUN sudo chmod +x /entrypoint.sh

# Expose ports
EXPOSE 22 9870 8088 9864

# Set entrypoint
ENTRYPOINT ["/entrypoint.sh"]

```

> #1 Base image
ubuntu:22.04 를 베이스로 하여 이미지를 빌드합니다. 따로 명시하지 않으면 작업 컴퓨터에 맞추어 arm64 기반 이미지를 사용합니다.

# Install necessary packages
패키지 관리 도구를 업데이트하고, 필요한 패키지들을 설치합니다. openjdk-11-jdk, wget, ssh, rsync, sudo 를 설치합니다.

# Create Hadoop user
Hadoop을 실행할 사용자 계정을 분리합니다. 기본적으로 루트 계정에서 하둡 서비스를 로드하지 못하도록 되어있으며 하둡을 위한 별도의 사용자를 권장합니다. 이를 통해 파일 시스템과 프로세스에 대한 권한을 잘 관리할 수 있습니다

# Set environment variables
도커 이미지를 빌드할때 사용되는 환경 변수를 설정합니다. 이 환경변수는 해당 스크립트가 수행되는 쉘에서만 적용됩니다.

# Download and install Hadoop
하둡을 다운로드하고 하둡 파일이 있는 디렉토리 및 하부 디렉토리에 대한 소유자와 그룹을 hadoop, hadoop으로 변경합니다.

# Change user
유저를 hadoop으로 바꾸어 다음 명령을 수행합니다.

# Configure SSH
ssh 키 쌍을 생성하고 공개키를 authorized_keys 파일에 추가합니다. 이 파일에 대한 읽기 쓰기 권한을 ‘hadoop’ 계정에게만 부여합니다

# Set environment variables in .bashrc
이미지 빌드 과정 외에 컨테이너에서 쉘을 사용할 때 환경변수를 사용할 수 있도록 .bashrc 에 명령어들을 추가합니다.

# Add Hadoop configuration files
미리 만들어논 하둡의 설정 파일들을 복사합니다.

# Configure JAVA_HOME in Hadoop environment
자바 환경변수를 선언하는 문자열을 하둡 환경설정을 위한 쉘 스크립트에 추가합니다. [hadoop-env.sh](http://hadoop-env.sh) 스크립트가 수행될 때 추가한 문장이 수행됩니다.

# Format HDFS namenode
하둡 파일시스템을 위한 디렉토리를 만들고, 소유자와 그룹을 설정합니다. 
hdfs를 실행하여 namenode를 포맷합니다. 초기화 역할입니다.

# Add entrypoint script
미리 만들어 놓은 [entrypoint.sh](http://entrypoint.sh) 파일을 복사합니다. 파일을 실행 가능하도록 권한을 변경합니다.

# Expose ports
22, 9870, 8088, 9864 포트를 개방해야함을 알려줍니다. 실제로 이미지를 RUN 할 때 명령어를 입력하여 포트를 매핑합니다.

# Set entrypoint
`ENTRYPOINT`로 설정된 스크립트는 컨테이너가 시작될 때 항상 실행됩니다.
> 

- entrypoint.sh

```bash
#!/bin/bash

# Start SSH service as root
sudo service ssh start

# Set Hadoop environment variables for users
export JAVA_HOME=/usr/lib/jvm/java-11-openjdk-arm64
export HADOOP_HOME=/usr/local/hadoop
export HADOOP_INSTALL=$HADOOP_HOME
export HADOOP_MAPRED_HOME=$HADOOP_HOME
export HADOOP_COMMON_HOME=$HADOOP_HOME
export HADOOP_HDFS_HOME=$HADOOP_HOME
export HADOOP_YARN_HOME=$HADOOP_HOME
export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native
export PATH=$PATH:$HADOOP_HOME/sbin:$HADOOP_HOME/bin
export HADOOP_OPTS="-Djava.library.path=$HADOOP_HOME/lib/native"

# Start HDFS services
if [ -x "$HADOOP_HOME/sbin/start-dfs.sh" ]; then
  echo "Starting HDFS services..."
  $HADOOP_HOME/sbin/start-dfs.sh
else
  echo "start-dfs.sh not found or not executable."
fi

# Start YARN services
if [ -x "$HADOOP_HOME/sbin/start-yarn.sh" ]; then
  echo "Starting YARN services..."
  $HADOOP_HOME/sbin/start-yarn.sh
else
  echo "start-yarn.sh not found or not executable."
fi

# Keep container running
echo "Container is running. Press Ctrl+C to stop."
tail -f /dev/null
```

> #!/bin/bash
이 파일은 배치파일입니다

# Start SSH service as root
ssh 서비스를 시작합니다.

# Set Hadoop environment variables for users
하둡 환경변수를 설정합니다. 대부분 기본값은 $HADOOP_HOME 라고합니다. 다만 명시하였습니다.

# Start HDFS services
$HADOOP_HOME/sbin/start-dfs.sh 을 실행합니다. 
이 배치 스크립트에 의해 namenod, datanod 데몬이 실행됩니다.

# Start YARN services
$HADOOP_HOME/sbin/start-yarn.sh 을 실행합니다.
리소스 매니저와 노드매니저 데몬이 실행됩니다.

# Keep container running
작업이 없더라도 컨테이너가 중단되지 않도록 합니다.
> 

- core-site.xml

```xml
<configuration>
    <property>
        <name>fs.defaultFS</name>
        <value>hdfs://localhost:9000</value>
    </property>
</configuration>
```

> 디폴트 파일 시스템, 하둡 파일시스템 서버를 위한 주소를 설정합니다.
> 

- hdfs-site.xml

```xml
<configuration>
    <property>
        <name>dfs.replication</name>
        <value>1</value>
    </property>
    <property>
        <name>dfs.namenode.name.dir</name>
        <value>file:///usr/local/hadoop/data/namenode</value>
    </property>
    <property>
        <name>dfs.datanode.data.dir</name>
        <value>file:///usr/local/hadoop/data/datanode</value>
    </property>
</configuration>

```

> 복제 개수를 설정합니다.
namenode, datanode에 대한 디렉토리를 설정합니다.
> 

- mapred-site.xml

```bash
<configuration>
    <property>
        <name>mapreduce.framework.name</name>
        <value>yarn</value>
    </property>
</configuration>

```

> MapReduce 작업은 yarn을 통해 수행됩니다.
> 

- yarn-site.xml

```bash
<configuration>
    <property>
        <name>yarn.nodemanager.aux-services</name>
        <value>mapreduce_shuffle</value>
    </property>
</configuration>

```

> -
> 

- java -version

```bash
openjdk version "11.0.23" 2024-04-16
OpenJDK Runtime Environment (build 11.0.23+9-post-Ubuntu-1ubuntu122.04.1)
OpenJDK 64-Bit Server VM (build 11.0.23+9-post-Ubuntu-1ubuntu122.04.1, mixed mode)
```

### 이미지 빌드 및 컨테이너 적재를 위한 명령

- 이미지 빌드

> docker build -t single-node-hadoop .
> 

- 이미지로부터 컨테이너 적재

> docker run -d --name hadoop-container -v ~/hadoop_data:/usr/local/hadoop/data -p 9870:9870 -p 8088:8088 -p 9864:9864 -p 2222:22 single-node-hadoop
> 

- 도커 가상머신 포트 포워딩

> 9870:9870 -p 8088:8088 -p 9864:9864 -p 2222:22 
호스트 포트 : 도커 데스크탑 포트
NameNode 웹 인터페이스 서버는 9870은 포트를 listen 합니다
NameNode 서버는 9000 포트를 listen 합니다
DataNode  웹 인터페이스 서버는 9864 포트를 listen 합니다
DataNode 서버는 9866 포트를 listen 합니다
ResourceManager 웹 인터페이스 서버는  8088 포트를 listen 합니다.
> 

- ssh를 통해 포트 포워딩 예시 확인

> ssh -p 2222 hadoop@localhost의 동작 원리
도커 데스크탑은 2222번 포트에 대한 데몬으로서 2222번 포트를 listening하고있다.
localhost:2222 로 ssh 연결을 시도할 경우 도커 데스크탑의 22번 포트로 포워딩된다.
NAT의 경우 ip와 포트번호를 통해 포트 포워딩을 한다. 도커 데스크탑은 브릿지 연결을 통해 포트 포워딩을 한다.
결국 22번 포트에 사용자 정보와 함께 ssh 연결을 시도하고 성공한다. 다른 포트에 대해서도 마찬가지이며
> 

### HDFS 명령 수행

- 디렉토리 생성, 파일 업로드, 파일 읽기

> 현재 작업 경로(”/usr/local/hadoop/data”)에서 파일을 생성합니다.
echo "apple banana grape" > localfile.txt

하둡 파일 시스템에 디렉토리를 생성합니다.
hdfs dfs -mkdir /user

/user 디렉토리에 localfile.txt 파일을 업로드합니다.
hdfs dfs -put localfile.txt /user

업로드 이후 하둡 파일 시스템의 루트에서부터 하위 디렉토리 정보를 확인합니다.
hdfs dfs -ls -R /

/user/localfile.txt 를 열어 내용을 확인합니다.
hdfs dfs -cat /user/locafile.txt
> 

### 기타

> docker inspect hadoop
docker network inspect bridge
> 

두 명령어를 통해 도커 데스크탑의 네트워크 정보를 확인할 수 있습니다.

- ssh 연결

```xml
ssh -p 2222 [hadoop@192.168.0.19](mailto:hadoop@192.168.0.19)
```

연결이 이렇게 되는 이유는 간단하다! 브릿지 네트워크로 연결되어있기 때문에 이렇게 연결해야하며, 명령어는 다음과 같이 해석할 수 있다.

> [localhost](http://localhost) == 192.168.0.19와 동일하다 (내 랩탑이 속한 네트워크에서 내 랩탑의 ip주소)
> 

ssh -p 1200 hadoop@localhost

ssh -p 1200 [hadoop@192.168.0.19](mailto:hadoop@192.168.0.19)

즉, ssh를 통해 내 주소의 1200포트로 연결을 시도하면 도커 가상머신의 22번 포트로 연결이 이루어지도록 도커 컨테이너가 작동중입니다.

다음 두 명령어를 활용하여 도커의 포트 매핑 정보 및 여러 설정 사항을 확인할 수 있습니다.

> docker inspect *hadoop*
docker network inspect bridge
>